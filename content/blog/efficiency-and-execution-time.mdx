---
title: Eficiencia y tiempo de ejecuciÃ³n de un algoritmo
description: Para resolver un determinado problema siempre van a existir varios algoritmos diferentes. El problema es, Â¿con quÃ© criterio elegimos cuÃ¡l utilizar?
image: /images/blog/complexity/complexity-pic.webp
date: "2023-09-30"
author: jeremiasarriondo
categories:
  - Programming
---

Para resolver un determinado problema siempre van a existir diferentes algoritmos posibles.

El problema es: Â¿con quÃ© criterio elegimos cuÃ¡l utilizar?
En primer instancia tal vez podemos pensar en algunos de los siguientes puntos:

- Que el algoritmo sea fÃ¡cil de entender, codificar y depurar
- Que el algoritmo se ejecute lo mÃ¡s rÃ¡pido posible
- Que el algoritmo haga â€œbuen usoâ€ de la memoria
- Que sea eficiente (utilizaciÃ³n Ã³ptima de los recursos del sistema
  donde se ejecutarÃ¡ el algoritmo)

Â¿CÃ³mo medimos el tiempo que tarda en ejecutarse? Â¿Horas, minutos,
segundos, milisegundos, nano? Depende del contexto.

Una forma de comparar algoritmos serÃ­a entonces hacerlos correr en la misma mÃ¡quina y luego ver cuÃ¡l tardÃ³ menos en completar su tarea.
El problema con este acercamiento es que solo podemos garantizar el mismo resultado en el futuro si las condiciones de ejecuciÃ³n siempre serÃ¡n exactamente las mismas.
TendrÃ­amos que usar la misma computadora, con el mismo lenguaje, el mismo compilador, el mismo procesador, misma memoria, misma
temperatura, etc.

## Â¿CÃ³mo medimos el tiempo de ejecuciÃ³n de un algoritmo?

Podemos definir el tiempo de ejecuciÃ³n como una funciÃ³n de la
entrada, es decir de las caracterÃ­sticas de los datos que
debemos procesar.
Para eso vamos a usar un modelo de mÃ¡quina simplificada.

Una mÃ¡quina simplificada nos permite hacer una anÃ¡lisis teÃ³rico
en donde:

- Toda instrucciÃ³n elemental tiene el mismo costo
- Todo acceso a memoria tiene el mismo costo

Entonces, vamos a definir el tiempo de ejecuciÃ³n como una
funciÃ³n de la entrada **T(n)**, donde no depende de la entrada
exacta, sino de su **tamaÃ±o**.

El interÃ©s de comparar algoritmos surge para problemas grandes.
Para problemas suficientemente chicos no suele ser tan importante quÃ© algoritmo se utiliza.

Dado que para distintos problemas el concepto de grande varÄ±Ìa,
realizaremos un anÃ¡lisis asintÃ³tico.

- Si n es el tamaÃ±o de la entrada, nos preguntaremos cÃ³mo se
  comporta el algoritmo cuando `n â†’ âˆ`.

Ahora pensemos, dado un algoritmo en particular, Â¿cÃ³mo calculamos cuÃ¡nto tarda?
Contaremos la cantidad de **operaciones elementales (OE)**.

<Callout>
  ğŸ’¡ Â¿QuÃ© es una **OE**? Aquellas que el procesador realiza en una cantidad de
  tiempo acotada por una constante (que no depende del tamaÃ±o de la entrada).
</Callout>

## Hablemos sobre el mejor caso, peor caso y caso promedio

Para usar el peor caso, tenemos:

> T(n)=mÃ¡ximo valor del tiempo de ejecuciÃ³n para entradas de tamaÃ±o n

Como T(n) depende del compilador, la mÃ¡quina que usamos y otros
factores no es posible expresarlo en segundos u otra unidad estÃ¡ndar
de tiempo. Solo vamos a poder hacer observaciones del tipo: â€œel tiempo de ejecuciÃ³n de tal algoritmo es proporcional a n2â€

## NotaciÃ³n asintÃ³tica

Usaremos la notaciÃ³n para hacer referencia a la velocidad de crecimiento de los valores de una funciÃ³n.

Por ejemplo `T(n)` es un programa de `O(n2)` significa que para `n >= 0` y `c` constante entonces se cumple que `T(n)<= cn2`,
Vamos a hacer un anÃ¡lisis asintÃ³tico porque a medida que van creciendo, distintos algoritmos pueden diferir en el tiempo que tardan en resolver el mismo problema.

Â¿Por quÃ© es importante que los algoritmos sean asintÃ³ticamente eficientes?

| n Complejidad | 10       | 20       | 30       | 40          | 50            | 60               |
| ------------- | -------- | -------- | -------- | ----------- | ------------- | ---------------- |
| n             | 0,00001â€ | 0,00002â€ | 0,00003â€ | 0,00004â€    | 0,00005â€      | 0,00006â€         |
| nÂ²            | 0,0001â€  | 0,0004â€  | 0,0009â€  | 0,0016â€     | 0,0025â€       | 0,0036â€          |
| nÂ³            | 0,001â€   | 0,008â€   | 0,027â€   | 0,064â€      | 0,125â€        | 0,216â€           |
| nâµ            | 0,1â€     | 3,2â€     | 24,3â€    | 1,7â€™        | 5,2â€™          | 13,0â€™            |
| 2â¿            | 0,001â€   | 1,0â€     | 17,9â€™    | 12,7 dÃ­as   | 35,7 aÃ±os     | 366 siglos       |
| 3â¿            | 0,059â€   | 58,0â€™    | 65 aÃ±os  | 3855 siglos | 2\*10â¸ siglos | 1,3\*10Â¹Â³ siglos |

> fuente: Aho, Hopcroft, Ullman

Entonces, el orden de `T (n)` expresa el comportamiento asintÃ³tico.
Expresiones comunes son: orden logarÄ±Ìtimico, lineal, cuadrÃ¡tico,
exponencial, etc.
Vamos a presentar tres cotas para comportamiento asintÃ³tico. El objetivo
del estudio de la complejidad algorÄ±Ìtmica es poder establecer estas cotas.
Tenemos:

- `O(T (n))` (O grande), cota superior. â€œSeâ€ cuanto va a tardar como mÃ¡ximo.

- `Î©(T (n))` (omega), cota inferior. â€œSeâ€ cuanto va a tardar como mÃ­nimo.

- `Î˜(T (n))` (theta), orden exacto. â€œSeâ€ ambas cosas.

## ClasificaciÃ³n de complejidades de â€œmejorâ€ a â€œpeorâ€

- O(1): complejidad constante.
- O(log (n)): complejidad logarÄ±Ìtmica.
- O(n): complejidad lineal (y cerca: O(n log (n))).
- O(nÂ²): complejidad cuadrÃ¡tica.
- O(nÂ³): complejidad cÃºbica.
- O(náµ), k â‰¥ 1: complejidad polinomial.
- O(2â¿): complejidad exponencial.

<Image
  src="/images/blog/complexity/time-to-execute.webp"
  alt="Eficiencia y tiempo de ejecuciÃ³n de un algoritmo"
  width={1607}
  height={946}
/>

<Callout>
En general : 1 < log (n) < náµ (k â‰¥ 1) < kâ¿ < n! < nâ¿
(donde f < g significa que la funciÃ³n g crece mÃ¡s rÃ¡pido que f ).
</Callout>

## Practiquemos

1. Calculemos el tiempo de ejecuciÃ³n de un algoritmo sencillo e indiquemos su Orden en el peor caso para el algoritmo.

```python
suma = 0
for x in range(n):
	suma += 1
```

- Se inicializa **`suma`** en 0, lo que toma un tiempo constante.
- El bucle **`for`** se ejecuta n veces, donde n es el valor de entrada.
- En cada iteraciÃ³n, se realiza una operaciÃ³n de suma que toma un tiempo constante O(1).

El tiempo total de ejecuciÃ³n (T(n)) se puede calcular multiplicando el nÃºmero de iteraciones (n) por el tiempo que toma realizar las operaciones dentro del bucle (O(1)):

`T(n) = n * O(1)`

`T(n) = O(n)`

El tiempo de ejecuciÃ³n del algoritmo es lineal en funciÃ³n de n. Por lo tanto, el orden en el peor caso de este algoritmo es O(n). Esto significa que el tiempo de ejecuciÃ³n crece linealmente con el tamaÃ±o de la entrada n.

2. Ahora realicemos un segundo y Ãºltimo caso:

```python
suma = 0
for x in range(n):
    for y in range(x, n):
        suma += 1
```

- El primer bucle **`for`** se ejecuta n veces, donde n es el valor de entrada.
- Para cada iteraciÃ³n del primer bucle, hay un segundo bucle **`for`** que se ejecuta desde x hasta n, donde x varÃ­a de 0 a n-1.

Para calcular el tiempo total de ejecuciÃ³n (T(n)), debemos sumar el tiempo que toma el segundo bucle **`for`** en cada iteraciÃ³n del primer bucle **`for`**. El segundo bucle **`for`** se ejecuta n veces en la primera iteraciÃ³n, n-1 veces en la segunda iteraciÃ³n, n-2 veces en la tercera iteraciÃ³n, y asÃ­ sucesivamente hasta 1 vez en la Ãºltima iteraciÃ³n.

El tiempo total de ejecuciÃ³n se puede calcular como una suma:

`T(n) = n + (n - 1) + (n - 2) + ... + 1`

Esto es una serie aritmÃ©tica que se puede simplificar usando la fÃ³rmula de la suma de los primeros n nÃºmeros naturales:

`T(n) = (n * (n + 1)) / 2`

El orden en el peor caso de este algoritmo es O(n^2) porque el tiempo de ejecuciÃ³n crece cuadrÃ¡ticamente con respecto al tamaÃ±o de la entrada n.

Otra manera de expresar el tiempo de ejecuciÃ³n es la siguiente manera:

`T(n) = c + n * (n - x * c1) => O(n2)`

- "c" representa un tiempo constante para operaciones fuera de los bucles.
- "n" es el nÃºmero de iteraciones del bucle exterior.
- "n - x \* c1" representa el nÃºmero de iteraciones del bucle interior en cada iteraciÃ³n del bucle exterior.

La expresiÃ³n indica que el tiempo de ejecuciÃ³n total se compone de un tÃ©rmino constante "c" mÃ¡s un tÃ©rmino que crece cuadrÃ¡ticamente con respecto a "n". Por lo tanto, el orden en el peor caso sigue siendo O(n^2), ya que el tÃ©rmino dominante es el cuadrÃ¡tico en funciÃ³n de "n".

En resumen, la complejidad computacional es una herramienta Ãºtil para analizar y comparar algoritmos en tÃ©rminos de su eficiencia en tiempo. En estos ejemplos, queda claro cÃ³mo un pequeÃ±o cambio en la estructura del algoritmo puede tener un impacto significativo en su tiempo de ejecuciÃ³n y complejidad. Es importante seleccionar algoritmos eficientes segÃºn las necesidades especÃ­ficas de nuestra aplicaciÃ³n y considerar cÃ³mo se comportan en diferentes tamaÃ±os de entrada.
